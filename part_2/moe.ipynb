{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### 简介\n",
    "Tokenization 的主要目的是将文本分解成更小的单位(Tokens)，减小模型输入数据的内在结构复杂度(从句子变为单词序列)，从而简化模型训练的难度。同时将字符的序列转化为Token序号的序列，便于模型输入。\n",
    "\n",
    "Tokenization 首先确定语言的词表划分粒度，一般可分为：\n",
    "* 字符级：将文本分解为字符。\n",
    "* 单词级：将文本分解为单词。\n",
    "* 子词级：将单词进一步分解为更小的有意义单元（如前缀、后缀）。\n",
    "\n",
    "之后使用预定义的规则来识别 tokens, 或使用统计或机器学习技术来识别最优的 token 切分方式。例如，BPE（Byte Pair Encoding）或 SentencePiece。\n",
    "\n",
    "最后实现一组文本序列和Tokens序列之间相互转化的函数，即可完成Tokenization部分。\n",
    "\n",
    "### 实验要求\n",
    "\n",
    "1. 实现字符级切分的简单tokenizer， 由 字符表， 字符到token的 encoder()函数 和 token到字符的 decoder() 函数组成。\n",
    "2. 调用 现有的tokenizer实现，比如openai 的tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataPath:str\n",
    "        ):\n",
    "        with open(dataPath,\"r\",encoding=\"utf-8\") as f:\n",
    "            self.dataset = f.read()\n",
    "        self.generate_vocabulary()\n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        \"\"\"\n",
    "        unique_chars = sorted(set(self.dataset))\n",
    "        self.char2index = {char: index for index, char in enumerate(unique_chars)}\n",
    "        self.index2char = {index: char for index, char in enumerate(unique_chars)}\n",
    "        \n",
    "        \n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        sentence : str,\n",
    "        ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input  : \"ABCD\"\n",
    "        output : Tensor([0,1,2,3]) \n",
    "\n",
    "        注意: 为了后续实验方便，输出Tensor的数据类型dtype 为torch.long。\n",
    "        \"\"\"\n",
    "        # 开始标记\n",
    "        tokens = [0]\n",
    "        for char in sentence:\n",
    "            tokens.append(self.char2index[char])\n",
    "            \n",
    "        # 结束标记\n",
    "        tokens.append(0)\n",
    "        return torch.tensor(tokens, dtype=torch.long)\n",
    "        \n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        tokens : torch.Tensor,\n",
    "        ) -> str:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input : Tensor([0,1,2,3]) \n",
    "        output : \"ABCD\"\n",
    "        \"\"\"\n",
    "        # 去掉开始和结束标记    \n",
    "        indices = tokens[1:-1]\n",
    "        # 转换为字符\n",
    "        chars = [self.index2char[index] for index in indices]\n",
    "        return \"\".join(chars)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 dataloader 和 dataset\n",
    "\n",
    "为了高效加载数据，我们需要把输入文件接入 PyTorch 的数据加载器中。在这里我们定义 `ShakespeareDataset` 类用于加载数据集，用 PyTorch 的 `DataLoader` 类来实现数据加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, filepath, tokenizer, chunk_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        self.encoded = self.tokenizer.encode(text)\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded) - self.chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: 提取一段文本(长度为 chunk_size）作为输入，以及这段文本的每一个字符的下一个字符作为标签\n",
    "        # example(not correspond to real text): chunk = tensor([ 0, 20, 49, 58, 59])\n",
    "        #         label = tensor([20, 49, 58, 59, 19])\n",
    "        # decoded chunk: \"The \"\n",
    "        # decoded label: \"he T\"\n",
    "        chunk = self.encoded[idx:idx+self.chunk_size] # 一段文本\n",
    "        label = self.encoded[idx+1:idx+self.chunk_size+1]\n",
    "\n",
    "        return chunk, label\n",
    "\n",
    "tokenizer = Tokenizer(dataPath=\"input.txt\")\n",
    "\n",
    "def create_dataloader(filepath, tokenizer, chunk_size, batch_size, shuffle=True):\n",
    "    dataset = ShakespeareDataset(filepath, tokenizer, chunk_size)\n",
    "    train_dataset,val_dataset = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),len(dataset)-int(len(dataset)*0.8)])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "#train_dataloader,val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=200, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力的计算公式为：\n",
    "$$\n",
    "Head = Attention(x)=Softmax(M\\cdot QK^T)V\\\\\n",
    "Q=xW_{q},K=xW_{k}, V=xW_{v}\n",
    "$$\n",
    "这里实现的一些数学技巧可以参见attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, seq_len:int, embed_size:int, hidden_size:int):\n",
    "        super().__init__()\n",
    "        # embed_size: dimension for input embedding vector\n",
    "        # hidden_size: dimension for hidden vector. eg. x:(..., embed_size) --to_q--> query_vector:(..., hidden_size)\n",
    "\n",
    "        # a triangular bool matrix for mask\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        \n",
    "        # TODO: init three matrix, to_q, to_k, to_v.\n",
    "        self.to_q = nn.Linear(embed_size, hidden_size) # embed_size -> hidden_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        # return (batch_size, seq_len, hidden_size)\n",
    "        # TODO: implement the attention mechanism\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # 计算Q,K,V\n",
    "        query = self.to_q(inputs)\n",
    "        key = self.to_q(inputs)\n",
    "        value = self.to_q(inputs)\n",
    "        \n",
    "        # 计算注意力的分数\n",
    "        attention = torch.bmm(query, key.transpose(1, 2)) / (embed_size ** 0.5) \n",
    "        \n",
    "        # mask\n",
    "        mask = self.tril[:seq_len, :seq_len].unsqueeze(0) # (1, seq_len, seq_len)\n",
    "        attention = attention.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        # softmax\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        \n",
    "        output = torch.bmm(attention, value).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer中使用的注意力机制时会使用多个注意力头，期望每个注意力头能够注意到不同的信息。\n",
    "所以实际公式需要修改如下\n",
    "$$\n",
    "MultiHeadAttention(x)=[Head_0, Head_1,...,Head_h]W_o\\\\\n",
    "Head_i = Attention(x)=Softmax(M\\cdot Q_iK_i^T)V_i\\\\\n",
    "Q_i=xW_{iq},K=xW_{ik}, V=xW_{iv}\n",
    "$$\n",
    "在搭建网络的过程中，同学们可能会用到nn.ModuleList这个库，每个$Head_i$的计算可以直接使用上面已经实现的单头注意力计算。\n",
    "最后对于这些注意力头再使用一个简单的线性层/矩阵$W_o$汇总信息即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    # MultiHeadAttention is consist of many HeadAttention output.\n",
    "    # concat all this head attention output o_i, then merge them with a projection matrix W_o, as [o_1, o_2, ...] x W_o\n",
    "    # The reason for using multi-head attention is that we want each head to be able to extract different features\n",
    "    def __init__(self, n_heads:int, head_size:int, seq_len:int, embed_size:int):\n",
    "        # n_heads is the number of head attention\n",
    "        # head_size is the hidden_size in each HeadAttention\n",
    "        super().__init__()\n",
    "        head_size = embed_size // n_heads # \n",
    "        #TODO: implement heads and projection\n",
    "        self.heads = nn.ModuleList(\n",
    "            [HeadAttention(seq_len, embed_size, head_size) for _ in range(n_heads)]\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Linear(n_heads * head_size, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size), make sure embed_size=n_heads x head_size\n",
    "        # return: (batch_size, seq_len, embed_size)\n",
    "        # TODO:\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # 每个head attention\n",
    "        head_outputs = [head(inputs) for head in self.heads]\n",
    "        concat_output = torch.cat(head_outputs, dim=-1)\n",
    "        output = self.projection(concat_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 专家网络 Expert\n",
    "\n",
    "Expert即为标准Transformer中的FeedForward模块。\n",
    "\n",
    "在经过MultiHeadAttention 模块后，seq_len中的每一个Embedding都对应了前文信息的加权求和。在经过FeedForward模块时，模型对每一个位置的Embedding进行了两次线性变换和一次非线性变换，可以视为对当前语境下的信息进行加工。知识编辑的一些研究表明，FeedForword 模块参数包含了大量的事实性知识。\n",
    "\n",
    "一个直观的想法是，类比于MultiHeadAttention，我们在每一层训练多个FeedForward模块，对于不同位置的Embedding使用不同的FeedForward模块处理对应的信息。就好像每层有多个Expert,每个Expert都负责处理一类数据的深加工，因此我们称FeedForward为Expert。\n",
    "\n",
    "实现方面:\n",
    "\n",
    "FeedForward层由两层简单的线性层组成，对于一个(batch_size, seq_len, embed_size)输入的向量x\n",
    "只在最后一个维度上进行计算，以实现词的特征维度上的交互(注意力机制是词之间的交互)。\n",
    "其首先用一个线性层将x最后一维扩大至原先4倍，然后继续用一个线性层还原回原先的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, embed_size:int):\n",
    "        super().__init__()\n",
    "        #TODO: init two linear layer\n",
    "        self.linear1 = nn.Linear(embed_size, embed_size * 4)\n",
    "        self.linear2 = nn.Linear(embed_size * 4, embed_size)\n",
    "        nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        nn.init.xavier_uniform_(self.linear2.weight) # 初始化权重\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: (batch_size, seq_len, embed_size)\n",
    "        # -> mid: (batch_size, seq_len, 4 x embed_size)\n",
    "        # -> outputs: (batch_size, seq_len, embed_size)\n",
    "        output = F.relu(self.linear1(inputs))\n",
    "        output = self.linear2(output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选通网络 TopkRouter\n",
    "\n",
    "在实现了单个Expert后，我们要设计一个选通网络决策每个Embedding要使用那个Expert计算\n",
    "\n",
    "\n",
    "### 为了说明选通网络的实现方式，我们定义一下记号：\n",
    "\n",
    "inputs.shape = [batch_size, seq_len, embed_size] = [1, 8, 16] \n",
    "\n",
    "即输入有batch_size=1个数据点，该数据有seq_len长度的context，即包含seq_len=8个Embedding，每个Embedding长度为embed_dim=16。\n",
    "\n",
    "记 num_expert = 4, 即该层包含 num_expert 个并列的Expert。\n",
    "\n",
    "记 active_expert = 2, 即计算每个Embedding仅有 active_expert 个Expert 参与计算。\n",
    "\n",
    "### 选通网络计算\n",
    "对于有seq_len=8的数据，如果每个Expert都参与计算每一个Embedding，那么一共需要计算 seq_len*embed_size = 32 次， 这极大的增加了模型计算量，因此我们往往只激活其中的active_experts个Expert，这要求我们对每一个Embedding计算最合适的active_experts个 Expert。\n",
    "\n",
    "对于单个Expert 的原版Transformer来说：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = FeedForward(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "对于多个Expert的网络：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = \\sum_{i \\in range(num\\_model)} \\alpha_{i} Expert_{i}(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_{i} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "    1 & Expert_{i}  \\text{is selected} \\\\\n",
    "    0 & Expert_{i}  \\text{is not selected} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "将$\\{\\alpha_0,\\alpha_1,\\dots,\\alpha_{num_experts-1}\\}$记为向量$\\alpha$:\n",
    "$$\n",
    "outputs[0,seq] = \\alpha \\cdot \\{Expert_i(inputs[0,seq])\\}\n",
    "$$\n",
    "\n",
    "一个选通0,2号Expert的$\\alpha$的例子是$[1,0,1,0]$\n",
    "\n",
    "问题在于如何求得 $\\alpha$, 对于一个Embedding ，我们使用神经网络对每个Expert打分，在根据分数计算$\\alpha$\n",
    "\n",
    "$$\n",
    "score[0,seq] = MLP(inputs[0,seq])  \\\\\n",
    "\\alpha = topK(score[0,seq])\n",
    "$$\n",
    "\n",
    "例如：\n",
    "\n",
    "$$\n",
    "score[0,seq] = [11.32,1.54,14.83,-1.90] \\\\\n",
    "\\alpha = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "从优化的角度来说，$\\alpha$取前k大的分数的下标（即argmax），这个操作是不可导的，这里我们用之前在\"attention.ipynb\"中提到的技巧处理这里的计算。\n",
    "\n",
    "$$\n",
    "mask(score[0,seq]) = [11.32,-inf,14.83,-inf] \\\\\n",
    "\\alpha = softmax(mask(score[0,seq])) = [0.028,0,0.971,0] \\\\\n",
    "index = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "我们用这个$\\alpha$和$index$用做选通网络."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First define the top k router module\n",
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, embed_size, num_experts, active_experts):\n",
    "        ## TODO\n",
    "        ## embed_size : dimension of embedding \n",
    "        ## num_experts : how many Experts per layer\n",
    "        ## active_experts: only active_experts out of num_experts are selected to process Embeddings per token.\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, embed_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_size * 4, num_experts)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        ## 完成这部分时，注意使用Softmax()对router_output做标准化。同时注意这部分所用操作的可导性。\n",
    "        ## 输入值\n",
    "        ## inputs is the output tensor from multihead self attention block, shape (B:batch size, T: seq_len, C: embed_size)\n",
    "        ## 返回值\n",
    "        ## router_output: normalized weight of Experts, 即教程中的 \\alpha\n",
    "        ## indices:   index of selected Experts, 即教程中的 index\n",
    "        \n",
    "        score = self.mlp(inputs)\n",
    "        topk_indices = torch.topk(score, self.active_experts, dim=-1).indices\n",
    "        \n",
    "        masked_score = torch.zeros_like(score, dtype=torch.bool)\n",
    "        masked_score.scatter_(dim=-1, index=topk_indices, value=True)\n",
    "        score = score.masked_fill(~masked_score, float('-inf'))\n",
    "        \n",
    "        router_output = F.softmax(score, dim=-1).to(device)\n",
    "        indices = topk_indices\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 稀疏专家网络 SparseMoE\n",
    "\n",
    "![moe](./moeSparse.png)\n",
    "\n",
    "在定义完Expert 和 TopkRouter后，我们可以定义SparseMoE模块。\n",
    "\n",
    "在前向过程中，对于inputs.shape = [Batch_size,seq_len,embed_size]第二维度seq_len个Embedding,我们先利用TopkRouter计算出选通专家序号indices以及专家权重router_output。\n",
    "\n",
    "我们将Embedding通过选通的Expert得出active_expert个新的Embedding，然后使用router_output的作为权重对新的Embedding加权求和作为输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self, embed_size:int, num_experts:int, active_experts:int):\n",
    "        ## TODO\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.experts = nn.ModuleList([Expert(embed_size) for _ in range(num_experts)])\n",
    "        self.router = TopkRouter(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        router_output, indices = self.router(inputs)\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # inputs: (batch_size, seq_len, embed_size)\n",
    "        # router_output: (batch_size, seq_len, num_experts)\n",
    "        # indices: (batch_size, seq_len, active_experts)\n",
    "        final_output = torch.zeros_like(inputs)\n",
    "        \n",
    "        # Reshape input\n",
    "        flat_inputs = inputs.view(-1, inputs.size(-1)) # (batch_size * seq_len, embed_size)\n",
    "        flat_router_output = router_output.view(-1, router_output.size(-1)) # (batch_size * seq_len, num_experts)\n",
    "        \n",
    "        for i, expert in enumerate(self.experts):\n",
    "            # 创建mask\n",
    "            expert_mask = (indices == i).any(dim=-1) # (batch_size, seq_len)\n",
    "            flat_mask = expert_mask.view(-1) # (batch_size * seq_len)\n",
    "            \n",
    "            if flat_mask.any():\n",
    "                expert_input = flat_inputs[flat_mask]\n",
    "                expert_output = expert(expert_input)\n",
    "                \n",
    "                gating_scores = flat_router_output[flat_mask, i].unsqueeze(1)\n",
    "                weighted_expert_output = expert_output * gating_scores\n",
    "                \n",
    "                final_output[expert_mask] += weighted_expert_output.squeeze(1)\n",
    "                \n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer由一层层的block堆叠而成，其中每个block的结构从模型的结构图展开中可以看到，由LayerNorm，Masked multi head attention，(SparseMoE)FeedForward组成。\n",
    "\n",
    "对于一个表示句子的输入向量x，其首先会经过Layer Normalization层.\n",
    "Layer Normalization 层对于一个 句子个数x句子长度x单词向量维度 的输入 x, 会在最后两维上进行规范化处理，起到稳定训练的作用。\n",
    "\n",
    "$$\n",
    "LN(x)=\\frac{x-mean(x)}{\\sqrt{var(x)+\\epsilon}}\\cdot\\gamma+\\beta\n",
    "$$\n",
    "\n",
    "其中mean和var都是在最后两个维度上进行的，layernorm的实现同学们可以直接调用nn.LayerNorm\n",
    "经过layernorm层后，再经过Mask multi head attention层之后，会在+号处再次和原始的输入进行相加，这样的做法能够提高训练的稳定性。有兴趣的同学可以从梯度角度思考原因，或者搜索残差连接相关资料进行学习。\n",
    "之后再同样经过一层layernorm和feedforwad之后，就可以得到block块的输出了。\n",
    "即 x' = x+MHA(LN(x)), y = FFN(LN(x'))+x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    # Transformer basic block, consist of MultiHeadAttention, FeedForward and layer normalization\n",
    "    def __init__(self, embed_size:int, n_heads:int, seq_len:int, num_experts:int, active_experts:int):\n",
    "        super().__init__()\n",
    "        # TODO: implement block structure\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(n_heads, embed_size//n_heads, seq_len, embed_size)\n",
    "        self.moe = SparseMoE(embed_size, num_experts, active_experts)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        #TODO: forward with residual connection\n",
    "        \n",
    "        x = self.ln1(inputs)\n",
    "        x = self.mha(x) + x\n",
    "        x = self.ln2(x)\n",
    "        x = self.moe(x) + x\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoETransformer(nn.Module):\n",
    "    # Transformer decoder, consist of \n",
    "    # token embedding layer and position_embedding(position_embedding 可以理解为对位置编码，感兴趣的同学可以查阅原文，这里可以看为vocab_len = seq_len的Embedding)\n",
    "    # a stack of Transformer basic block\n",
    "    # a layernorm and output linear layer\n",
    "    def __init__(self, vocab_size:int, seq_len:int, embed_size:int, n_layers:int, n_heads:int, num_experts:int, active_experts:int):\n",
    "        # vocab_size is the number of word in vocabulary dict\n",
    "        # seq_len is the sequence length/sentence length\n",
    "        # embed_size is the embedding vector dimension\n",
    "        super().__init__()\n",
    "        # TODO: \n",
    "        self.seq_len = seq_len\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(seq_len, embed_size)\n",
    "        \n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(embed_size, n_heads, seq_len, num_experts, active_experts) for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm = nn.LayerNorm(embed_size)\n",
    "        self.output_linear = nn.Linear(embed_size, vocab_size)\n",
    "        nn.init.xavier_uniform_(self.output_linear.weight)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        # labels: the (ground) true output \n",
    "        # TODO: implement the forward function of the transformer\n",
    "\n",
    "        # inputs:(batch_size, seq_len, )\n",
    "        batch_size, seq_len, = inputs.shape\n",
    "        # embedding:(batch_size, seq_len, embed_size)\n",
    "        \n",
    "        embedding = self.token_embedding(inputs) + self.position_embedding(torch.arange(seq_len, device=device))\n",
    "\n",
    "        # attens:(batch_size, seq_len, embed_size)\n",
    "        for block in self.blocks:\n",
    "            attens = block(embedding)\n",
    "\n",
    "        # logits:(batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        logits = self.output_linear(self.layernorm(attens))\n",
    "\n",
    "        # compute the loss\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, seq_len, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * seq_len, vocab_size)\n",
    "            labels = labels.view(batch_size * seq_len)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n",
    "        device = next(self.parameters()).device  \n",
    "        inputs = inputs.to(device)\n",
    "        if inputs.size(1) > self.seq_len:\n",
    "            inputs = inputs[:, :self.seq_len]\n",
    "        generated = inputs\n",
    "        for _ in range(max_new_tokens):\n",
    "            if generated.size(1) > self.seq_len:\n",
    "                generated_input = generated[:, -self.seq_len:]\n",
    "            else:\n",
    "                generated_input = generated\n",
    "            logits, _ = self.forward(generated_input)\n",
    "            last_logits = logits[:, -1, :]  \n",
    "            next_token_ids = torch.argmax(last_logits, dim=-1)  \n",
    "            next_token_ids = next_token_ids.unsqueeze(-1)  \n",
    "            generated = torch.cat([generated, next_token_ids], dim=1)  \n",
    "        return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练循环\n",
    "\n",
    "如果你已经完成了模型定义等内容，训练的过程实际上在高度封装的 Pytorch 库中非常简单, 因为你并不需要写对应的反向传播。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss \n",
    "\n",
    "Loss 用来**衡量**模型预测与真实值之间的**差距**。\n",
    "\n",
    "常见的几个 Loss 函数：\n",
    "\n",
    "* 交叉熵：$\\text{CrossEntropy Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$\n",
    "* 均方误差：$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "* 绝对误差：$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n",
    "\n",
    "不同的 loss 对应不同的优化目标，如果写错 loss 函数会导致模型不收敛/性能很差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练循环\n",
    "\n",
    "当我们写好 Optimizer 和 Loss 之后，对应的训练循环就十分简单了。\n",
    "\n",
    "我们只需要做以下事情：\n",
    "\n",
    "* 从 dataloader 里面拿到一个 batch 的数据以及标签\n",
    "* 将数据送入模型，进行前向传播\n",
    "* 拿到模型输出的 logits\n",
    "* 将 logits 和 标签进行 loss 计算\n",
    "* 用 Optimizer \n",
    "    * 清空梯度\n",
    "    * 反向传播\n",
    "    * 更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epoch, device):\n",
    "    # Optimizer 会根据模型的输出和真实标签计算梯度，然后利用反向传播算法更新模型的参数。\n",
    "    # 在本实验中你可以将 Optimizer 视作黑盒，只需要知道如何使用即可。\n",
    "    # 找一个合适的 Optimizer。对不同的任务，模型，最适合的优化器是不一样的，你可以先尝试最常用的 Adam，如果有兴趣可以看看其他的优化器。\n",
    "    # docs see: https://pytorch.org/docs/stable/optim.html \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    from tqdm import tqdm\n",
    "    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # TODO: implement the training process, and compute the training loss and validation loss\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs.clone().detach()\n",
    "        targets = targets.clone().detach()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch} Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, epoch, device):\n",
    "    model.eval()\n",
    "    # TODO: 实现验证函数。与训练函数类似，但不需要计算梯度。\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch} Validation Loss: {total_loss / len(dataloader)}')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [01:00<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.6684618652413743\n",
      "Epoch 0 Validation Loss: 2.4295509468425402\n",
      "Epoch 0 Train Loss: 2.6684618652413743, Valid Loss: 2.4295509468425402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:28<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.346512783557997\n",
      "Epoch 1 Validation Loss: 2.241438692266291\n",
      "Epoch 1 Train Loss: 2.346512783557997, Valid Loss: 2.241438692266291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:28<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.182877531839073\n",
      "Epoch 2 Validation Loss: 2.1099873759529806\n",
      "Epoch 2 Train Loss: 2.182877531839073, Valid Loss: 2.1099873759529806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:28<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 2.0759357859235292\n",
      "Epoch 3 Validation Loss: 2.0229078206149014\n",
      "Epoch 3 Train Loss: 2.0759357859235292, Valid Loss: 2.0229078206149014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:27<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 1.9947466762787704\n",
      "Epoch 4 Validation Loss: 1.9518765579570423\n",
      "Epoch 4 Train Loss: 1.9947466762787704, Valid Loss: 1.9518765579570423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:26<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 1.9448655526572411\n",
      "Epoch 5 Validation Loss: 1.9097212596373125\n",
      "Epoch 5 Train Loss: 1.9448655526572411, Valid Loss: 1.9097212596373125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:25<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.8957026502408019\n",
      "Epoch 6 Validation Loss: 1.864795166795904\n",
      "Epoch 6 Train Loss: 1.8957026502408019, Valid Loss: 1.864795166795904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:55<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.8578219802007763\n",
      "Epoch 7 Validation Loss: 1.8292660474777223\n",
      "Epoch 7 Train Loss: 1.8578219802007763, Valid Loss: 1.8292660474777223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [01:06<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 1.8255552419828713\n",
      "Epoch 8 Validation Loss: 1.800321713360873\n",
      "Epoch 8 Train Loss: 1.8255552419828713, Valid Loss: 1.800321713360873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:27<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 1.798594554083063\n",
      "Epoch 9 Validation Loss: 1.7740756966850975\n",
      "Epoch 9 Train Loss: 1.798594554083063, Valid Loss: 1.7740756966850975\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1550663/906350044.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could pick my lance\n",
      "To the the shall the she shall the the shall the the shall the the shall the the shall the the shal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=50, batch_size=4096)\n",
    "model = SparseMoETransformer(vocab_size=len(tokenizer.char2index), seq_len=50, embed_size=64, n_layers=3, n_heads=8, num_experts=8, active_experts=2).to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "def run(model, train_dataloader, valid_dataloader, device, epochs=10):\n",
    "    # model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_dataloader, epoch, device)\n",
    "        valid_loss = validate(model, valid_dataloader, epoch, device)\n",
    "        print(f'Epoch {epoch} Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "#TODO: 用 matplotlib plot 训练过程中的 loss 变化\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('loss.png')\n",
    "\n",
    "train_losses, val_losses = run(model, train_dataloader, val_dataloader, device, epochs=10)\n",
    "\n",
    "plot_loss(train_losses, val_losses)\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "print(tokenizer.decode(model.generate(\"I could pick my lance\",max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
