{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### 简介\n",
    "Tokenization 的主要目的是将文本分解成更小的单位(Tokens)，减小模型输入数据的内在结构复杂度(从句子变为单词序列)，从而简化模型训练的难度。同时将字符的序列转化为Token序号的序列，便于模型输入。\n",
    "\n",
    "Tokenization 首先确定语言的词表划分粒度，一般可分为：\n",
    "* 字符级：将文本分解为字符。\n",
    "* 单词级：将文本分解为单词。\n",
    "* 子词级：将单词进一步分解为更小的有意义单元（如前缀、后缀）。\n",
    "\n",
    "之后使用预定义的规则来识别 tokens, 或使用统计或机器学习技术来识别最优的 token 切分方式。例如，BPE（Byte Pair Encoding）或 SentencePiece。\n",
    "\n",
    "最后实现一组文本序列和Tokens序列之间相互转化的函数，即可完成Tokenization部分。\n",
    "\n",
    "### 实验要求\n",
    "\n",
    "1. 实现字符级切分的简单tokenizer， 由 字符表， 字符到token的 encoder()函数 和 token到字符的 decoder() 函数组成。\n",
    "2. 调用 现有的tokenizer实现，比如openai 的tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataPath:str\n",
    "        ):\n",
    "        with open(dataPath,\"r\",encoding=\"utf-8\") as f:\n",
    "            self.dataset = f.read()\n",
    "        self.generate_vocabulary()\n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        \"\"\"\n",
    "        unique_chars = sorted(set(self.dataset))\n",
    "        self.char2index = {char: index for index, char in enumerate(unique_chars)}\n",
    "        self.index2char = {index: char for index, char in enumerate(unique_chars)}\n",
    "        \n",
    "        \n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        sentence : str,\n",
    "        ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input  : \"ABCD\"\n",
    "        output : Tensor([0,1,2,3]) \n",
    "\n",
    "        注意: 为了后续实验方便，输出Tensor的数据类型dtype 为torch.long。\n",
    "        \"\"\"\n",
    "        # 开始标记\n",
    "        # tokens = [0]\n",
    "        tokens = []\n",
    "        for char in sentence:\n",
    "            tokens.append(self.char2index[char])\n",
    "            \n",
    "        # 结束标记\n",
    "        # tokens.append(0)\n",
    "        return torch.tensor(tokens, dtype=torch.long)\n",
    "        \n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        tokens : torch.Tensor,\n",
    "        ) -> str:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input : Tensor([0,1,2,3]) \n",
    "        output : \"ABCD\"\n",
    "        \"\"\"\n",
    "        # 去掉开始和结束标记    \n",
    "        indices = tokens[1:-1]\n",
    "        # 转换为字符\n",
    "        chars = [self.index2char[index] for index in indices]\n",
    "        return \"\".join(chars)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 dataloader 和 dataset\n",
    "\n",
    "为了高效加载数据，我们需要把输入文件接入 PyTorch 的数据加载器中。在这里我们定义 `ShakespeareDataset` 类用于加载数据集，用 PyTorch 的 `DataLoader` 类来实现数据加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, filepath, tokenizer, chunk_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        self.encoded = self.tokenizer.encode(text)\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded) - self.chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: 提取一段文本(长度为 chunk_size）作为输入，以及这段文本的每一个字符的下一个字符作为标签\n",
    "        # example(not correspond to real text): chunk = tensor([ 0, 20, 49, 58, 59])\n",
    "        #         label = tensor([20, 49, 58, 59, 19])\n",
    "        # decoded chunk: \"The \"\n",
    "        # decoded label: \"he T\"\n",
    "        chunk = self.encoded[idx:idx+self.chunk_size] # 一段文本\n",
    "        label = self.encoded[idx+1:idx+self.chunk_size+1]\n",
    "\n",
    "        return chunk, label\n",
    "\n",
    "tokenizer = Tokenizer(dataPath=\"input.txt\")\n",
    "\n",
    "def create_dataloader(filepath, tokenizer, chunk_size, batch_size, shuffle=True):\n",
    "    dataset = ShakespeareDataset(filepath, tokenizer, chunk_size)\n",
    "    train_dataset,val_dataset = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),len(dataset)-int(len(dataset)*0.8)])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "#train_dataloader,val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=200, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力的计算公式为：\n",
    "$$\n",
    "Head = Attention(x)=Softmax(M\\cdot QK^T)V\\\\\n",
    "Q=xW_{q},K=xW_{k}, V=xW_{v}\n",
    "$$\n",
    "这里实现的一些数学技巧可以参见attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, seq_len:int, embed_size:int, hidden_size:int):\n",
    "        super().__init__()\n",
    "        # embed_size: dimension for input embedding vector\n",
    "        # hidden_size: dimension for hidden vector. eg. x:(..., embed_size) --to_q--> query_vector:(..., hidden_size)\n",
    "\n",
    "        # a triangular bool matrix for mask\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        \n",
    "        # TODO: init three matrix, to_q, to_k, to_v.\n",
    "        self.to_q = nn.Linear(embed_size, hidden_size) # embed_size -> hidden_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        # return (batch_size, seq_len, hidden_size)\n",
    "        # TODO: implement the attention mechanism\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # 计算Q,K,V\n",
    "        query = self.to_q(inputs)\n",
    "        key = self.to_q(inputs)\n",
    "        value = self.to_q(inputs)\n",
    "        \n",
    "        # 计算注意力的分数\n",
    "        attention = torch.bmm(query, key.transpose(1, 2)) / (embed_size ** 0.5) \n",
    "        \n",
    "        # mask\n",
    "        mask = self.tril[:seq_len, :seq_len].unsqueeze(0) # (1, seq_len, seq_len)\n",
    "        attention = attention.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        # softmax\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        \n",
    "        output = torch.bmm(attention, value).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer中使用的注意力机制时会使用多个注意力头，期望每个注意力头能够注意到不同的信息。\n",
    "所以实际公式需要修改如下\n",
    "$$\n",
    "MultiHeadAttention(x)=[Head_0, Head_1,...,Head_h]W_o\\\\\n",
    "Head_i = Attention(x)=Softmax(M\\cdot Q_iK_i^T)V_i\\\\\n",
    "Q_i=xW_{iq},K=xW_{ik}, V=xW_{iv}\n",
    "$$\n",
    "在搭建网络的过程中，同学们可能会用到nn.ModuleList这个库，每个$Head_i$的计算可以直接使用上面已经实现的单头注意力计算。\n",
    "最后对于这些注意力头再使用一个简单的线性层/矩阵$W_o$汇总信息即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    # MultiHeadAttention is consist of many HeadAttention output.\n",
    "    # concat all this head attention output o_i, then merge them with a projection matrix W_o, as [o_1, o_2, ...] x W_o\n",
    "    # The reason for using multi-head attention is that we want each head to be able to extract different features\n",
    "    def __init__(self, n_heads:int, head_size:int, seq_len:int, embed_size:int):\n",
    "        # n_heads is the number of head attention\n",
    "        # head_size is the hidden_size in each HeadAttention\n",
    "        super().__init__()\n",
    "        head_size = embed_size // n_heads # \n",
    "        #TODO: implement heads and projection\n",
    "        self.heads = nn.ModuleList(\n",
    "            [HeadAttention(seq_len, embed_size, head_size) for _ in range(n_heads)]\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Linear(n_heads * head_size, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size), make sure embed_size=n_heads x head_size\n",
    "        # return: (batch_size, seq_len, embed_size)\n",
    "        # TODO:\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # 每个head attention\n",
    "        head_outputs = [head(inputs) for head in self.heads]\n",
    "        concat_output = torch.cat(head_outputs, dim=-1)\n",
    "        output = self.projection(concat_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 专家网络 Expert\n",
    "\n",
    "Expert即为标准Transformer中的FeedForward模块。\n",
    "\n",
    "在经过MultiHeadAttention 模块后，seq_len中的每一个Embedding都对应了前文信息的加权求和。在经过FeedForward模块时，模型对每一个位置的Embedding进行了两次线性变换和一次非线性变换，可以视为对当前语境下的信息进行加工。知识编辑的一些研究表明，FeedForword 模块参数包含了大量的事实性知识。\n",
    "\n",
    "一个直观的想法是，类比于MultiHeadAttention，我们在每一层训练多个FeedForward模块，对于不同位置的Embedding使用不同的FeedForward模块处理对应的信息。就好像每层有多个Expert,每个Expert都负责处理一类数据的深加工，因此我们称FeedForward为Expert。\n",
    "\n",
    "实现方面:\n",
    "\n",
    "FeedForward层由两层简单的线性层组成，对于一个(batch_size, seq_len, embed_size)输入的向量x\n",
    "只在最后一个维度上进行计算，以实现词的特征维度上的交互(注意力机制是词之间的交互)。\n",
    "其首先用一个线性层将x最后一维扩大至原先4倍，然后继续用一个线性层还原回原先的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, embed_size:int):\n",
    "        super().__init__()\n",
    "        #TODO: init two linear layer\n",
    "        self.linear1 = nn.Linear(embed_size, embed_size * 4)\n",
    "        self.linear2 = nn.Linear(embed_size * 4, embed_size)\n",
    "        nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        nn.init.xavier_uniform_(self.linear2.weight) # 初始化权重\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: (batch_size, seq_len, embed_size)\n",
    "        # -> mid: (batch_size, seq_len, 4 x embed_size)\n",
    "        # -> outputs: (batch_size, seq_len, embed_size)\n",
    "        output = F.relu(self.linear1(inputs))\n",
    "        output = self.linear2(output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选通网络 TopkRouter\n",
    "\n",
    "在实现了单个Expert后，我们要设计一个选通网络决策每个Embedding要使用那个Expert计算\n",
    "\n",
    "\n",
    "### 为了说明选通网络的实现方式，我们定义一下记号：\n",
    "\n",
    "inputs.shape = [batch_size, seq_len, embed_size] = [1, 8, 16] \n",
    "\n",
    "即输入有batch_size=1个数据点，该数据有seq_len长度的context，即包含seq_len=8个Embedding，每个Embedding长度为embed_dim=16。\n",
    "\n",
    "记 num_expert = 4, 即该层包含 num_expert 个并列的Expert。\n",
    "\n",
    "记 active_expert = 2, 即计算每个Embedding仅有 active_expert 个Expert 参与计算。\n",
    "\n",
    "### 选通网络计算\n",
    "对于有seq_len=8的数据，如果每个Expert都参与计算每一个Embedding，那么一共需要计算 seq_len*embed_size = 32 次， 这极大的增加了模型计算量，因此我们往往只激活其中的active_experts个Expert，这要求我们对每一个Embedding计算最合适的active_experts个 Expert。\n",
    "\n",
    "对于单个Expert 的原版Transformer来说：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = FeedForward(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "对于多个Expert的网络：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = \\sum_{i \\in range(num\\_model)} \\alpha_{i} Expert_{i}(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_{i} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "    1 & Expert_{i}  \\text{is selected} \\\\\n",
    "    0 & Expert_{i}  \\text{is not selected} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "将$\\{\\alpha_0,\\alpha_1,\\dots,\\alpha_{num_experts-1}\\}$记为向量$\\alpha$:\n",
    "$$\n",
    "outputs[0,seq] = \\alpha \\cdot \\{Expert_i(inputs[0,seq])\\}\n",
    "$$\n",
    "\n",
    "一个选通0,2号Expert的$\\alpha$的例子是$[1,0,1,0]$\n",
    "\n",
    "问题在于如何求得 $\\alpha$, 对于一个Embedding ，我们使用神经网络对每个Expert打分，在根据分数计算$\\alpha$\n",
    "\n",
    "$$\n",
    "score[0,seq] = MLP(inputs[0,seq])  \\\\\n",
    "\\alpha = topK(score[0,seq])\n",
    "$$\n",
    "\n",
    "例如：\n",
    "\n",
    "$$\n",
    "score[0,seq] = [11.32,1.54,14.83,-1.90] \\\\\n",
    "\\alpha = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "从优化的角度来说，$\\alpha$取前k大的分数的下标（即argmax），这个操作是不可导的，这里我们用之前在\"attention.ipynb\"中提到的技巧处理这里的计算。\n",
    "\n",
    "$$\n",
    "mask(score[0,seq]) = [11.32,-inf,14.83,-inf] \\\\\n",
    "\\alpha = softmax(mask(score[0,seq])) = [0.028,0,0.971,0] \\\\\n",
    "index = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "我们用这个$\\alpha$和$index$用做选通网络."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First define the top k router module\n",
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, embed_size, num_experts, active_experts):\n",
    "        ## TODO\n",
    "        ## embed_size : dimension of embedding \n",
    "        ## num_experts : how many Experts per layer\n",
    "        ## active_experts: only active_experts out of num_experts are selected to process Embeddings per token.\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, embed_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_size * 4, num_experts)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        ## 完成这部分时，注意使用Softmax()对router_output做标准化。同时注意这部分所用操作的可导性。\n",
    "        ## 输入值\n",
    "        ## inputs is the output tensor from multihead self attention block, shape (B:batch size, T: seq_len, C: embed_size)\n",
    "        ## 返回值\n",
    "        ## router_output: normalized weight of Experts, 即教程中的 \\alpha\n",
    "        ## indices:   index of selected Experts, 即教程中的 index\n",
    "        \n",
    "        score = self.mlp(inputs)\n",
    "        topk_indices = torch.topk(score, self.active_experts, dim=-1).indices\n",
    "        \n",
    "        masked_score = torch.zeros_like(score, dtype=torch.bool)\n",
    "        masked_score.scatter_(dim=-1, index=topk_indices, value=True)\n",
    "        score = score.masked_fill(~masked_score, float('-inf'))\n",
    "        \n",
    "        router_output = F.softmax(score, dim=-1).to(device)\n",
    "        indices = topk_indices\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 稀疏专家网络 SparseMoE\n",
    "\n",
    "![moe](./moeSparse.png)\n",
    "\n",
    "在定义完Expert 和 TopkRouter后，我们可以定义SparseMoE模块。\n",
    "\n",
    "在前向过程中，对于inputs.shape = [Batch_size,seq_len,embed_size]第二维度seq_len个Embedding,我们先利用TopkRouter计算出选通专家序号indices以及专家权重router_output。\n",
    "\n",
    "我们将Embedding通过选通的Expert得出active_expert个新的Embedding，然后使用router_output的作为权重对新的Embedding加权求和作为输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self, embed_size:int, num_experts:int, active_experts:int):\n",
    "        ## TODO\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.experts = nn.ModuleList([Expert(embed_size) for _ in range(num_experts)])\n",
    "        self.router = TopkRouter(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        router_output, indices = self.router(inputs)\n",
    "        batch_size, seq_len, embed_size = inputs.size()\n",
    "        \n",
    "        # inputs: (batch_size, seq_len, embed_size)\n",
    "        # router_output: (batch_size, seq_len, num_experts)\n",
    "        # indices: (batch_size, seq_len, active_experts)\n",
    "        final_output = torch.zeros_like(inputs)\n",
    "        \n",
    "        # Reshape input\n",
    "        flat_inputs = inputs.view(-1, inputs.size(-1)) # (batch_size * seq_len, embed_size)\n",
    "        flat_router_output = router_output.view(-1, router_output.size(-1)) # (batch_size * seq_len, num_experts)\n",
    "        \n",
    "        for i, expert in enumerate(self.experts):\n",
    "            # 创建mask\n",
    "            expert_mask = (indices == i).any(dim=-1) # (batch_size, seq_len)\n",
    "            flat_mask = expert_mask.view(-1) # (batch_size * seq_len)\n",
    "            \n",
    "            if flat_mask.any():\n",
    "                expert_input = flat_inputs[flat_mask]\n",
    "                expert_output = expert(expert_input)\n",
    "                \n",
    "                gating_scores = flat_router_output[flat_mask, i].unsqueeze(1)\n",
    "                weighted_expert_output = expert_output * gating_scores\n",
    "                \n",
    "                final_output[expert_mask] += weighted_expert_output.squeeze(1)\n",
    "                \n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer由一层层的block堆叠而成，其中每个block的结构从模型的结构图展开中可以看到，由LayerNorm，Masked multi head attention，(SparseMoE)FeedForward组成。\n",
    "\n",
    "对于一个表示句子的输入向量x，其首先会经过Layer Normalization层.\n",
    "Layer Normalization 层对于一个 句子个数x句子长度x单词向量维度 的输入 x, 会在最后两维上进行规范化处理，起到稳定训练的作用。\n",
    "\n",
    "$$\n",
    "LN(x)=\\frac{x-mean(x)}{\\sqrt{var(x)+\\epsilon}}\\cdot\\gamma+\\beta\n",
    "$$\n",
    "\n",
    "其中mean和var都是在最后两个维度上进行的，layernorm的实现同学们可以直接调用nn.LayerNorm\n",
    "经过layernorm层后，再经过Mask multi head attention层之后，会在+号处再次和原始的输入进行相加，这样的做法能够提高训练的稳定性。有兴趣的同学可以从梯度角度思考原因，或者搜索残差连接相关资料进行学习。\n",
    "之后再同样经过一层layernorm和feedforwad之后，就可以得到block块的输出了。\n",
    "即 x' = x+MHA(LN(x)), y = FFN(LN(x'))+x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    # Transformer basic block, consist of MultiHeadAttention, FeedForward and layer normalization\n",
    "    def __init__(self, embed_size:int, n_heads:int, seq_len:int, num_experts:int, active_experts:int):\n",
    "        super().__init__()\n",
    "        # TODO: implement block structure\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(n_heads, embed_size//n_heads, seq_len, embed_size)\n",
    "        self.moe = SparseMoE(embed_size, num_experts, active_experts)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        #TODO: forward with residual connection\n",
    "        \n",
    "        x = self.ln1(inputs)\n",
    "        x = self.mha(x) + x\n",
    "        x = self.ln2(x)\n",
    "        x = self.moe(x) + x\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoETransformer(nn.Module):\n",
    "    # Transformer decoder, consist of \n",
    "    # token embedding layer and position_embedding(position_embedding 可以理解为对位置编码，感兴趣的同学可以查阅原文，这里可以看为vocab_len = seq_len的Embedding)\n",
    "    # a stack of Transformer basic block\n",
    "    # a layernorm and output linear layer\n",
    "    def __init__(self, vocab_size:int, seq_len:int, embed_size:int, n_layers:int, n_heads:int, num_experts:int, active_experts:int):\n",
    "        # vocab_size is the number of word in vocabulary dict\n",
    "        # seq_len is the sequence length/sentence length\n",
    "        # embed_size is the embedding vector dimension\n",
    "        super().__init__()\n",
    "        # TODO: \n",
    "        self.seq_len = seq_len\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(seq_len, embed_size)\n",
    "        \n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(embed_size, n_heads, seq_len, num_experts, active_experts) for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm = nn.LayerNorm(embed_size)\n",
    "        self.output_linear = nn.Linear(embed_size, vocab_size)\n",
    "        nn.init.xavier_uniform_(self.output_linear.weight)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        # labels: the (ground) true output \n",
    "        # TODO: implement the forward function of the transformer\n",
    "\n",
    "        # inputs:(batch_size, seq_len, )\n",
    "        batch_size, seq_len, = inputs.shape\n",
    "        # embedding:(batch_size, seq_len, embed_size)\n",
    "        \n",
    "        embedding = self.token_embedding(inputs) + self.position_embedding(torch.arange(seq_len, device=device))\n",
    "\n",
    "        # attens:(batch_size, seq_len, embed_size)\n",
    "        for block in self.blocks:\n",
    "            attens = block(embedding)\n",
    "\n",
    "        # logits:(batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        logits = self.output_linear(self.layernorm(attens))\n",
    "\n",
    "        # compute the loss\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, seq_len, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * seq_len, vocab_size)\n",
    "            labels = labels.view(batch_size * seq_len)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n",
    "        device = next(self.parameters()).device  \n",
    "        inputs = inputs.to(device)\n",
    "        if inputs.size(1) > self.seq_len:\n",
    "            inputs = inputs[:, :self.seq_len]\n",
    "        generated = inputs\n",
    "        for _ in range(max_new_tokens):\n",
    "            if generated.size(1) > self.seq_len:\n",
    "                generated_input = generated[:, -self.seq_len:]\n",
    "            else:\n",
    "                generated_input = generated\n",
    "            logits, _ = self.forward(generated_input)\n",
    "            last_logits = logits[:, -1, :]  \n",
    "            next_token_ids = torch.argmax(last_logits, dim=-1)  \n",
    "            next_token_ids = next_token_ids.unsqueeze(-1)  \n",
    "            generated = torch.cat([generated, next_token_ids], dim=1)  \n",
    "        return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练循环\n",
    "\n",
    "如果你已经完成了模型定义等内容，训练的过程实际上在高度封装的 Pytorch 库中非常简单, 因为你并不需要写对应的反向传播。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss \n",
    "\n",
    "Loss 用来**衡量**模型预测与真实值之间的**差距**。\n",
    "\n",
    "常见的几个 Loss 函数：\n",
    "\n",
    "* 交叉熵：$\\text{CrossEntropy Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$\n",
    "* 均方误差：$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "* 绝对误差：$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n",
    "\n",
    "不同的 loss 对应不同的优化目标，如果写错 loss 函数会导致模型不收敛/性能很差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练循环\n",
    "\n",
    "当我们写好 Optimizer 和 Loss 之后，对应的训练循环就十分简单了。\n",
    "\n",
    "我们只需要做以下事情：\n",
    "\n",
    "* 从 dataloader 里面拿到一个 batch 的数据以及标签\n",
    "* 将数据送入模型，进行前向传播\n",
    "* 拿到模型输出的 logits\n",
    "* 将 logits 和 标签进行 loss 计算\n",
    "* 用 Optimizer \n",
    "    * 清空梯度\n",
    "    * 反向传播\n",
    "    * 更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epoch, device):\n",
    "    # Optimizer 会根据模型的输出和真实标签计算梯度，然后利用反向传播算法更新模型的参数。\n",
    "    # 在本实验中你可以将 Optimizer 视作黑盒，只需要知道如何使用即可。\n",
    "    # 找一个合适的 Optimizer。对不同的任务，模型，最适合的优化器是不一样的，你可以先尝试最常用的 Adam，如果有兴趣可以看看其他的优化器。\n",
    "    # docs see: https://pytorch.org/docs/stable/optim.html \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    from tqdm import tqdm\n",
    "    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # TODO: implement the training process, and compute the training loss and validation loss\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs.clone().detach()\n",
    "        targets = targets.clone().detach()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch} Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, epoch, device):\n",
    "    model.eval()\n",
    "    # TODO: 实现验证函数。与训练函数类似，但不需要计算梯度。\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch} Validation Loss: {total_loss / len(dataloader)}')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:29<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1784033950416095\n",
      "Epoch 0 Validation Loss: 1.8352133937931936\n",
      "Epoch 0 Train Loss: 2.1784033950416095, Valid Loss: 1.8352133937931936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:46<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.7230089491834877\n",
      "Epoch 1 Validation Loss: 1.6396693043205717\n",
      "Epoch 1 Train Loss: 1.7230089491834877, Valid Loss: 1.6396693043205717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:55<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.5927862628601914\n",
      "Epoch 2 Validation Loss: 1.5532492060180103\n",
      "Epoch 2 Train Loss: 1.5927862628601914, Valid Loss: 1.5532492060180103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:52<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.526343718658421\n",
      "Epoch 3 Validation Loss: 1.5053680246576258\n",
      "Epoch 3 Train Loss: 1.526343718658421, Valid Loss: 1.5053680246576258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:52<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 1.4866550368135576\n",
      "Epoch 4 Validation Loss: 1.4746374914405542\n",
      "Epoch 4 Train Loss: 1.4866550368135576, Valid Loss: 1.4746374914405542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:40<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 1.4599471525836798\n",
      "Epoch 5 Validation Loss: 1.4510948149436111\n",
      "Epoch 5 Train Loss: 1.4599471525836798, Valid Loss: 1.4510948149436111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:20<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.4401873809745513\n",
      "Epoch 6 Validation Loss: 1.4319208967029502\n",
      "Epoch 6 Train Loss: 1.4401873809745513, Valid Loss: 1.4319208967029502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:25<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.4247262933373246\n",
      "Epoch 7 Validation Loss: 1.4198580892807846\n",
      "Epoch 7 Train Loss: 1.4247262933373246, Valid Loss: 1.4198580892807846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:19<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 1.4123645225476753\n",
      "Epoch 8 Validation Loss: 1.4095901537925826\n",
      "Epoch 8 Train Loss: 1.4123645225476753, Valid Loss: 1.4095901537925826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1743/1743 [01:28<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 1.401994579151589\n",
      "Epoch 9 Validation Loss: 1.3985106493901769\n",
      "Epoch 9 Train Loss: 1.401994579151589, Valid Loss: 1.3985106493901769\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1664269/906350044.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could pick my lance\n",
      "That I will be so my lord.\n",
      "\n",
      "PETRUCHIO:\n",
      "The shall I shall be so man a son a man a sincent to the sea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=50, batch_size=512)\n",
    "model = SparseMoETransformer(vocab_size=len(tokenizer.char2index), seq_len=50, embed_size=64, n_layers=3, n_heads=8, num_experts=8, active_experts=2).to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "def run(model, train_dataloader, valid_dataloader, device, epochs=10):\n",
    "    # model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_dataloader, epoch, device)\n",
    "        valid_loss = validate(model, valid_dataloader, epoch, device)\n",
    "        print(f'Epoch {epoch} Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "#TODO: 用 matplotlib plot 训练过程中的 loss 变化\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('loss.png')\n",
    "\n",
    "train_losses, val_losses = run(model, train_dataloader, val_dataloader, device, epochs=10)\n",
    "\n",
    "plot_loss(train_losses, val_losses)\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "print(tokenizer.decode(model.generate(\"I could pick my lance\",max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
